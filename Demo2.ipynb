{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-vision pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (0.8.4)\n",
      "Requirement already satisfied: python-dotenv in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (1.0.1)\n",
      "Requirement already satisfied: Pillow in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (10.4.0)\n",
      "Requirement already satisfied: pydantic in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (2.9.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.160.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: tqdm in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arturtrebski/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai python-dotenv Pillow pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_lassa_pdfs():\n",
    "    # The base URL that hosts the PDFs\n",
    "    base_url = \"https://ncdc.gov.ng\"\n",
    "    # The specific page that lists all the Lassa fever situation reports\n",
    "    list_page_url = (\n",
    "        \"https://ncdc.gov.ng/diseases/sitreps/?cat=5&name=An%20update%20of%20Lassa%20fever%20outbreak%20in%20Nigeria\"\n",
    "    )\n",
    "    \n",
    "    # Create a local folder to store the PDFs\n",
    "    os.makedirs(\"pdfs\", exist_ok=True)\n",
    "    \n",
    "    # 1. Fetch the HTML\n",
    "    print(f\"Fetching list page: {list_page_url}\")\n",
    "    response = requests.get(list_page_url)\n",
    "    response.raise_for_status()  # raise an error if the HTTP request failed\n",
    "    \n",
    "    # 2. Parse the HTML\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # The table is inside <tbody>. Each row has multiple <td>, \n",
    "    # and the third <td> has the <a> with the PDF link\n",
    "    table_body = soup.find(\"tbody\")\n",
    "    if not table_body:\n",
    "        print(\"Could not find <tbody> on the page.\")\n",
    "        return\n",
    "    \n",
    "    rows = table_body.find_all(\"tr\")\n",
    "    if not rows:\n",
    "        print(\"No <tr> found inside <tbody>.\")\n",
    "        return\n",
    "\n",
    "    # For stats\n",
    "    total_found = 0\n",
    "    total_downloaded = 0\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) < 3:\n",
    "            # We expect 3 <td> in each row: (1) index, (2) description, (3) the PDF link\n",
    "            continue\n",
    "        \n",
    "        # The PDF link is in the third cell; let's get the <a>:\n",
    "        link_tag = cells[2].find(\"a\", href=True)\n",
    "        if not link_tag:\n",
    "            continue\n",
    "        \n",
    "        # The PDF URL is relative, e.g. \"/themes/common/files/sitreps/...\"\n",
    "        # We need to prepend https://ncdc.gov.ng\n",
    "        pdf_url = link_tag[\"href\"]\n",
    "        if pdf_url.startswith(\"/\"):\n",
    "            pdf_url = base_url + pdf_url\n",
    "        \n",
    "        # The \"download\" attribute often has the suggested filename\n",
    "        # or we can parse from the final part of the URL\n",
    "        download_name = link_tag.get(\"download\")  # e.g. \"An update of Lassa fever ... .pdf\"\n",
    "        \n",
    "        if not download_name:\n",
    "            # Fallback: parse the filename from the URL\n",
    "            download_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "        # Clean up the download name if needed\n",
    "        download_name = download_name.replace(\" \", \"_\")\n",
    "\n",
    "        total_found += 1\n",
    "        # 3. Download the PDF\n",
    "        # We'll skip if it already exists. Or you can overwrite by removing the check.\n",
    "        local_path = os.path.join(\"pdfs\", download_name)\n",
    "        if os.path.exists(local_path):\n",
    "            print(f\"Already downloaded: {download_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Downloading {pdf_url} -> {local_path}\")\n",
    "        try:\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            pdf_response.raise_for_status()\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(pdf_response.content)\n",
    "            total_downloaded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {pdf_url}: {e}\")\n",
    "\n",
    "    print(f\"Found {total_found} PDF links total. Downloaded {total_downloaded} new PDFs.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_lassa_pdfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pdf_files = os.listdir('PDFs')\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_lassa_files(folder_path):\n",
    "    \"\"\"\n",
    "    Renames 'An_update_of_Lassa_fever_outbreak_in_Nigeria_041124_45.pdf'\n",
    "    to 'Nigeria_04_Nov_24_W45.pdf', extracting day=04, month=11 => 'Nov', year=24,\n",
    "    and the week number 45.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder that contains the PDF files.\n",
    "    \"\"\"\n",
    "    # For mapping month number to short name\n",
    "    month_map = {\n",
    "        \"01\": \"Jan\", \"02\": \"Feb\", \"03\": \"Mar\", \"04\": \"Apr\",\n",
    "        \"05\": \"May\", \"06\": \"Jun\", \"07\": \"Jul\", \"08\": \"Aug\",\n",
    "        \"09\": \"Sep\", \"10\": \"Oct\", \"11\": \"Nov\", \"12\": \"Dec\",\n",
    "    }\n",
    "\n",
    "    folder = Path(folder_path)\n",
    "    for file_path in folder.iterdir():\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        if not file_path.suffix.lower() == \".pdf\":\n",
    "            continue\n",
    "        \n",
    "        old_name = file_path.name\n",
    "        # Example old_name: \"An_update_of_Lassa_fever_outbreak_in_Nigeria_041124_45.pdf\"\n",
    "        \n",
    "        # 1) Split on underscores\n",
    "        parts = old_name.split(\"_\")\n",
    "        # e.g. [\"An\",\"update\",\"of\",\"Lassa\",\"fever\",\"outbreak\",\"in\",\"Nigeria\",\"041124\",\"45.pdf\"]\n",
    "        \n",
    "        if len(parts) < 9:\n",
    "            # If the file name doesn't match the expected pattern, skip it\n",
    "            print(f\"Skipping file (unrecognized pattern): {old_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 2) The date chunk is parts[8] like \"041124\"\n",
    "        date_str = parts[8]  # \"041124\"\n",
    "        \n",
    "        # 3) The week chunk is in parts[9], but includes \".pdf\" at the end, e.g. \"45.pdf\"\n",
    "        week_str_pdf = parts[9]  # \"45.pdf\"\n",
    "        # Remove \".pdf\" from the end\n",
    "        if week_str_pdf.endswith(\".pdf\"):\n",
    "            week_str = week_str_pdf.replace(\".pdf\", \"\")\n",
    "        else:\n",
    "            print(f\"Skipping file (no .pdf in last part): {old_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 4) date_str should be 6 characters: DDMMYY\n",
    "        if len(date_str) != 6:\n",
    "            print(f\"Skipping file (date string not 6 chars): {old_name}\")\n",
    "            continue\n",
    "        dd = date_str[0:2]   # \"04\"\n",
    "        mm = date_str[2:4]   # \"11\"\n",
    "        yy = date_str[4:6]   # \"24\"\n",
    "        \n",
    "        # 5) Convert mm => month name\n",
    "        month_name = month_map.get(mm, \"???\" )  # fallback \"???\"\n",
    "        \n",
    "        # 6) Build new name\n",
    "        # e.g. \"Nigeria_04_Nov_24_W45.pdf\"\n",
    "        new_name = f\"Nigeria_{dd}_{month_name}_{yy}_W{week_str}.pdf\"\n",
    "        \n",
    "        new_path = folder / new_name\n",
    "        # 7) Rename the file\n",
    "        print(f\"Renaming:\\n  {old_name}\\n-> {new_name}\\n\")\n",
    "        file_path.rename(new_path)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    rename_lassa_files(\"PDFs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFs for 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted PDFs for 2024: ['Nigeria_04_Jan_24_W1.pdf', 'Nigeria_11_Jan_24_W2.pdf', 'Nigeria_18_Jan_24_W3.pdf', 'Nigeria_25_Jan_24_W4.pdf', 'Nigeria_01_Feb_24_W5.pdf', 'Nigeria_08_Feb_24_W6.pdf', 'Nigeria_15_Feb_24_W7.pdf', 'Nigeria_22_Feb_24_W8.pdf', 'Nigeria_29_Feb_24_W9.pdf', 'Nigeria_07_Mar_24_W10.pdf', 'Nigeria_14_Mar_24_W11.pdf', 'Nigeria_21_Mar_24_W12.pdf', 'Nigeria_28_Mar_24_W13.pdf', 'Nigeria_04_Apr_24_W14.pdf', 'Nigeria_11_Apr_24_W15.pdf', 'Nigeria_18_Apr_24_W16.pdf', 'Nigeria_25_Apr_24_W17.pdf', 'Nigeria_02_May_24_W18.pdf', 'Nigeria_09_May_24_W19.pdf', 'Nigeria_16_May_24_W20.pdf', 'Nigeria_23_May_24_W21.pdf', 'Nigeria_30_May_24_W22.pdf', 'Nigeria_06_Jun_24_W23.pdf', 'Nigeria_13_Jun_24_W24.pdf', 'Nigeria_20_Jun_24_W25.pdf', 'Nigeria_27_Jun_24_W26.pdf', 'Nigeria_04_Jul_24_W27.pdf', 'Nigeria_11_Jul_24_W28.pdf', 'Nigeria_18_Jul_24_W29.pdf', 'Nigeria_25_Jul_24_W30.pdf', 'Nigeria_01_Aug_24_W31.pdf', 'Nigeria_08_Aug_24_W32.pdf', 'Nigeria_15_Aug_24_W33.pdf', 'Nigeria_22_Aug_24_W34.pdf', 'Nigeria_29_Aug_24_W35.pdf', 'Nigeria_05_Sep_24_W36.pdf', 'Nigeria_12_Sep_24_W37.pdf', 'Nigeria_19_Sep_24_W38.pdf', 'Nigeria_26_Sep_24_W39.pdf', 'Nigeria_03_Oct_24_W40.pdf', 'Nigeria_10_Oct_24_W41.pdf', 'Nigeria_14_Oct_24_W42.pdf', 'Nigeria_21_Oct_24_W43.pdf', 'Nigeria_28_Oct_24_W44.pdf', 'Nigeria_04_Nov_24_W45.pdf', 'Nigeria_11_Nov_24_W46.pdf', 'Nigeria_18_Nov_24_W47.pdf', 'Nigeria_25_Nov_24_W48.pdf', 'Nigeria_02_Dec_24_W49.pdf', 'Nigeria_09_Dec_24_W50.pdf', 'Nigeria_16_Dec_24_W51.pdf', 'Nigeria_23_Dec_24_W52.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "all_pdfs = [f for f in os.listdir(\"PDFs\") if f.endswith(\".pdf\")]\n",
    "pdfs_2024 = [f for f in all_pdfs if \"_24_W\" in f]\n",
    "#print(\"PDFs for 2024:\", pdfs_2024)\n",
    "\n",
    "sorted_pdfs = sorted(pdfs_2024, key=lambda x: int(re.search(r'_W(\\d+)\\.pdf$', x).group(1)))\n",
    "print(\"Sorted PDFs for 2024:\", sorted_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf in sorted_pdfs:\n",
    "    input_pdf = os.path.join(\"PDFs\", pdf)\n",
    "    output_img = os.path.join(\"PDFs_Lines\", f\"Lines_{pdf.replace('.pdf','')}_page3.png\")\n",
    "    enhance_table_lines_from_pdf_hq(input_pdf, output_img, tr1=700, linelength1=1700,linegap1=100, toler1 = 10 , page_number=3, dpi=300) #length 40 was decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def hex_to_hsv(hex_color):\n",
    "    rgb = ImageColor.getcolor(hex_color, \"RGB\")\n",
    "    r, g, b = [x / 255.0 for x in rgb]\n",
    "    hsv = cv2.cvtColor(np.uint8([[[b * 255, g * 255, r * 255]]]), cv2.COLOR_BGR2HSV)[0][0]\n",
    "    return hsv\n",
    "\n",
    "def enhance_table_lines_from_pdf_hq(pdf_path, output_path,tr1, linelength1, linegap1,toler1, page_number=0, dpi=300):\n",
    "    \"\"\"\n",
    "    Enhances vertical column separators and draws horizontal lines at\n",
    "    top boundary, bottom boundary, and header bottom.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF.\n",
    "        output_path (str): Path to save the image (use .png).\n",
    "        page_number (int): Page to process (0-indexed).\n",
    "        dpi (int): Resolution for rendering the PDF page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "\n",
    "    # 1. Render the PDF page at high DPI\n",
    "    pix = page.get_pixmap(dpi=dpi) \n",
    "    img_pil = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    # Convert PIL Image to OpenCV BGR\n",
    "    img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 2. Convert to HSV to detect green rows\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    target_hsv = hex_to_hsv(\"#D8EDCF\")\n",
    "    tolerance = toler1\n",
    "    lower_green = np.array([max(0, target_hsv[0] - tolerance), 50, 50])\n",
    "    upper_green = np.array([min(179, target_hsv[0] + tolerance), 255, 255])\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    h_proj_green = np.sum(green_mask, axis=1)\n",
    "    green_row_indices = np.where(h_proj_green > 50)[0]\n",
    "\n",
    "    if len(green_row_indices) == 0:\n",
    "        print(\"No green rows detected.\")\n",
    "        return\n",
    "\n",
    "    top_boundary = green_row_indices[0]\n",
    "    bottom_boundary = green_row_indices[-1]\n",
    "\n",
    "    # 3. Header Row Detection (just above top_boundary)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    header_region = gray[:top_boundary, :]\n",
    "\n",
    "    # Use Otsu’s threshold instead of fixed 180\n",
    "    _, binary_header = cv2.threshold(header_region, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    h_proj_header = np.sum(binary_header, axis=1)\n",
    "\n",
    "    header_bottom = 0\n",
    "    for i in range(len(h_proj_header) - 1, 0, -1):\n",
    "        if h_proj_header[i] > 40:\n",
    "            header_bottom = i\n",
    "            break\n",
    "\n",
    "    # 4. Adaptive Thresholding in the table region\n",
    "    table_region = gray[top_boundary:bottom_boundary, :]\n",
    "    thresh_table = cv2.adaptiveThreshold(\n",
    "        table_region, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 3\n",
    "    )\n",
    "\n",
    "    # 5. Hough Lines to find vertical lines\n",
    "    # Increase or decrease threshold=775 if you get too few/many lines\n",
    "    lines = cv2.HoughLinesP(thresh_table, 1, np.pi / 180, threshold=tr1,\n",
    "                            minLineLength=linelength1, maxLineGap=linegap1)\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # Check near-vertical\n",
    "            if abs(x2 - x1) < 2:\n",
    "                # Adjust back to full image coordinates\n",
    "                vertical_lines.append((x1, y1 + top_boundary, x2, y2 + top_boundary))\n",
    "\n",
    "    # 6. Draw lines on the OpenCV image\n",
    "    # A) Draw the vertical lines from header_bottom to bottom_boundary\n",
    "    for x1, y1, x2, y2 in vertical_lines:\n",
    "        cv2.line(img, (x1, 350), (x2, bottom_boundary-185), (100, 100, 100), 1)\n",
    "   \n",
    "    print(header_bottom)\n",
    "    # B) Draw horizontal lines at:\n",
    "    #    - top_boundary\n",
    "    #    - bottom_boundary\n",
    "    #    - header_bottom\n",
    "    # We'll draw them across the full width of the image\n",
    "    height, width = img.shape[:2]\n",
    "    # color is (100,100,100); thickness=1 or 2 as you prefer\n",
    "    # Top boundary (green)\n",
    "    cv2.line(img, (0, top_boundary), (width, top_boundary), (0, 255, 0), 2)\n",
    "\n",
    "    # Bottom boundary (green)\n",
    "    cv2.line(img, (0, bottom_boundary), (width, bottom_boundary), (0, 255, 0), 2)\n",
    "\n",
    "    # Header bottom (red)\n",
    "    cv2.line(img, (0, header_bottom), (width, header_bottom), (0, 0, 255), 2)\n",
    "\n",
    "    # 7. Convert back to PIL and save\n",
    "    output_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    output_pil.save(output_path)\n",
    "\n",
    "    print(f\"Saved enhanced table to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "Saved enhanced table to: Lines_W1_boundaries.png\n",
      "405\n",
      "Saved enhanced table to: Lines_W2_boundaries.png\n",
      "407\n",
      "Saved enhanced table to: Lines_W3_boundaries.png\n",
      "410\n",
      "Saved enhanced table to: Lines_W4_boundaries.png\n",
      "402\n",
      "Saved enhanced table to: Lines_W12_boundaries.png\n",
      "407\n",
      "Saved enhanced table to: Lines_W22_boundaries.png\n",
      "408\n",
      "Saved enhanced table to: Lines_W26_boundaries.png\n",
      "427\n",
      "Saved enhanced table to: Lines_W32_boundaries.png\n",
      "430\n",
      "Saved enhanced table to: Lines_W42_boundaries.png\n",
      "399\n",
      "Saved enhanced table to: Lines_W52_boundaries.png\n"
     ]
    }
   ],
   "source": [
    "for week in [1,2,3,4,12,22,26,32,42,52]:\n",
    "    enhance_table_lines_from_pdf_hq(f\"PDFs/W{week}.pdf\", f\"Lines_W{week}_boundaries.png\", page_number=3, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiding text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code works well now! \n",
    "Crops images to the bottom of the table avoding the legend and also places vertical lines at correct positions. 2 of the tables had issues with the green rows being detected but can address that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def hex_to_hsv(hex_color):\n",
    "    rgb = ImageColor.getcolor(hex_color, \"RGB\")\n",
    "    r, g, b = [x / 255.0 for x in rgb]\n",
    "    hsv = cv2.cvtColor(\n",
    "        np.uint8([[[b * 255, g * 255, r * 255]]]),\n",
    "        cv2.COLOR_BGR2HSV\n",
    "    )[0][0]\n",
    "    return hsv\n",
    "\n",
    "def enhance_table_lines_from_pdf_hq(\n",
    "    pdf_path, \n",
    "    output_path,\n",
    "    tr1, \n",
    "    linelength1, \n",
    "    linegap1, \n",
    "    toler1, \n",
    "    page_number=0, \n",
    "    dpi=600\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhances vertical column separators and draws horizontal lines at\n",
    "    top boundary, bottom boundary, and header bottom. Uses morphological\n",
    "    filtering to remove small vertical text edges.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF.\n",
    "        output_path (str): Path to save the image (e.g. .png).\n",
    "        tr1 (int): HoughLinesP threshold.\n",
    "        linelength1 (int): HoughLinesP minLineLength.\n",
    "        linegap1 (int): HoughLinesP maxLineGap.\n",
    "        toler1 (int): Tolerance around the HSV hue for detecting green rows.\n",
    "        page_number (int): Which PDF page to process (0-indexed).\n",
    "        dpi (int): Rendering DPI for the PDF page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "\n",
    "    # 1. Render the PDF page at high DPI\n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    img_pil = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    # Convert PIL Image to OpenCV BGR\n",
    "    img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    height1, width1 = img.shape[:2]\n",
    "    total_pixels = height1 * width1\n",
    "    print(\"Total pixels =\", total_pixels)\n",
    "    # 2. Convert to HSV & detect green rows\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #target_hsv = hex_to_hsv(\"#D8EDCF\")\n",
    "    target_hsv = np.array([102, 12.66, 92.94], dtype=np.uint8)\n",
    "    tolerance = toler1\n",
    "    lower_green = np.array([max(0, target_hsv[0] - tolerance), 50, 50])\n",
    "    upper_green = np.array([min(179, target_hsv[0] + tolerance), 255, 255])\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    h_proj_green = np.sum(green_mask, axis=1)\n",
    "    green_row_indices = np.where(h_proj_green > 1000)[0]\n",
    "\n",
    "    if len(green_row_indices) == 0:\n",
    "        print(\"No green rows detected.\")\n",
    "        print(pdf_path)\n",
    "        #return\n",
    "\n",
    "    if len(green_row_indices) == 0:\n",
    "        top_boundary = 800\n",
    "        bottom_boundary = 4500\n",
    "    else:\n",
    "        top_boundary = green_row_indices[0] - 20\n",
    "        bottom_boundary = green_row_indices[-1] + 20\n",
    "    \n",
    "    # 3. Header Row Detection (just above top_boundary)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    header_region = gray[:top_boundary, :]\n",
    "\n",
    "    _, binary_header = cv2.threshold(\n",
    "        header_region, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )\n",
    "    h_proj_header = np.sum(binary_header, axis=1)\n",
    "\n",
    "    header_bottom = 0\n",
    "    for i in range(len(h_proj_header) - 1, 0, -1):\n",
    "        if h_proj_header[i] > 40:\n",
    "            header_bottom = i\n",
    "            break\n",
    "\n",
    "    # 4. Adaptive Thresholding in the table region\n",
    "    table_region = gray[top_boundary:bottom_boundary, :]\n",
    "    thresh_table = cv2.adaptiveThreshold(\n",
    "        table_region,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11,\n",
    "        3\n",
    "    )\n",
    "\n",
    "    #kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 40))\n",
    "    #cleaned = cv2.morphologyEx(thresh_table, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 5. Hough Lines to find vertical lines (using the filtered 'cleaned' image)\n",
    "    lines = cv2.HoughLinesP(\n",
    "        thresh_table,\n",
    "        1,\n",
    "        np.pi / 180,\n",
    "        threshold=tr1,\n",
    "        minLineLength=linelength1,\n",
    "        maxLineGap=linegap1\n",
    "    )\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            if abs(x2 - x1) < 5:\n",
    "                vertical_lines.append((x1, y1 + top_boundary, x2, y2 + top_boundary))\n",
    "\n",
    "    # 6. Draw vertical lines on the image\n",
    "    for x1, y1, x2, y2 in vertical_lines:\n",
    "        cv2.line(img, (x1, top_boundary-120), (x2, bottom_boundary+20), (100, 100, 100), 2)\n",
    "\n",
    "    #print(f\"Header bottom: {top_boundary}\")\n",
    "\n",
    "    # Crop the image so that it ends at bottom_boundary + 40\n",
    "    crop_bottom = bottom_boundary + 40\n",
    "    crop_bottom = min(crop_bottom, img.shape[0])\n",
    "    new_width = int(img.shape[1] * 0.58)  # keep left 58% of the image\n",
    "    img_cropped = img[:crop_bottom, :new_width]\n",
    "    \n",
    "    # 7. Convert back to PIL and save\n",
    "    output_pil = Image.fromarray(cv2.cvtColor(img_cropped, cv2.COLOR_BGR2RGB))\n",
    "    output_pil.save(output_path)\n",
    "\n",
    "    #print(f\"Saved enhanced table to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels = 34799360\n"
     ]
    }
   ],
   "source": [
    "pdf = \"Nigeria_14_Oct_24_W42.pdf\"\n",
    "input_pdf = os.path.join(\"PDFs\", pdf)\n",
    "output_img = os.path.join(\"PDFs_Lines\", f\"Lines_{pdf.replace('.pdf','')}_page3.png\")\n",
    "enhance_table_lines_from_pdf_hq(input_pdf, output_img, tr1=1000, linelength1=70,linegap1=70, toler1 = 10, page_number=3, dpi=600) #length 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels = 34806376\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34757631\n",
      "Total pixels = 34806376\n",
      "No green rows detected.\n",
      "PDFs/Nigeria_01_Aug_24_W31.pdf\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34799360\n",
      "Total pixels = 34806376\n",
      "No green rows detected.\n",
      "PDFs/Nigeria_28_Oct_24_W44.pdf\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n",
      "Total pixels = 34806376\n"
     ]
    }
   ],
   "source": [
    "for pdf in sorted_pdfs:\n",
    "    input_pdf = os.path.join(\"PDFs\", pdf)\n",
    "    output_img = os.path.join(\"PDFs_Lines\", f\"Lines_{pdf.replace('.pdf','')}_page3.png\")\n",
    "    enhance_table_lines_from_pdf_hq(input_pdf, output_img, tr1=1400, linelength1=79,linegap1=50, toler1 = 10, page_number=3, dpi=600) #length 40 was decent\n",
    "\n",
    "    # For DPI 300 tr1 = 850 was good, linelength = 1700, linegap = 100, toler =  10\n",
    "    # But need to find better one for DPI 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google AI LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google.genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a table titled \"Lassa Fever Situation Report\" showing the weekly and cumulative number of suspected and confirmed cases for 2024. The data is broken down by state and includes information on suspected cases, confirmed cases, trend, probable cases among healthcare workers (HCW), and deaths. The table covers Epi Week 12 of 2024 and the cumulative data for weeks 1-12.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import PIL.Image\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "image = PIL.Image.open('PDFs_Lines_Test/Lines_Nigeria_21_Mar_24_W12_page3.png')\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"What is this image?\", image])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 - outputting CSV-formatted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the Gemini client with your API key\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Define the prompt that instructs the model how to extract the table data.\n",
    "prompt_template = \"\"\"\n",
    "The provided image contains a table with a section labeled \"Current Week\". Your task is to extract the data from this section only and ignore any cumulative columns.\n",
    "The \"Current Week\" section has the following columns in this exact left-to-right order:\n",
    "1. States\n",
    "2. Suspected\n",
    "3. Confirmed\n",
    "4. Trend\n",
    "5. Probable\n",
    "6. HCW*\n",
    "7. Deaths (Confirmed Cases)\n",
    "\n",
    "Extract the numbers (or values) located under each column header. Return the results as a CSV-formatted table where:\n",
    "- The first row contains the headers exactly as listed above.\n",
    "- Each subsequent row corresponds to a State.\n",
    "- The last row is for the \"Total\" for all States.\n",
    "Ensure that all columns are present in the output, even if some cells are blank.\n",
    "Output the table in the same column order as given above.\n",
    "\"\"\"\n",
    "\n",
    "# Folder containing the PNG images\n",
    "image_folder = \"PDFs_Lines_Test\"\n",
    "\n",
    "# Get list of PNG images from the folder\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.png\"))\n",
    "\n",
    "if not image_paths:\n",
    "    print(f\"No PNG images found in the folder '{image_folder}'. Please check the folder name and path.\")\n",
    "else:\n",
    "    for image_path in image_paths:\n",
    "        print(\"Processing image:\", image_path)\n",
    "        \n",
    "        # Open the image using Pillow\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Call the Gemini model. We send the prompt along with the image as context.\n",
    "        # (Depending on the API, the image can be passed as part of the contents list.)\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                # Pass a list containing the prompt and the image.\n",
    "                # (The library is designed to accept multiple contents; if not, you may need to adapt this.)\n",
    "                contents=[prompt_template, image]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call for image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Print the extracted table data\n",
    "        print(\"Extracted table data:\")\n",
    "        print(response.text)\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 - using structured JSON outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in your .env file. Please add it and restart the notebook.\")\n",
    "\n",
    "# Initialize the Gemini client with your API key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Define the Pydantic model for one row of the table.\n",
    "# We use Field aliases so that the JSON keys match the column names exactly.\n",
    "class TableRow(BaseModel):\n",
    "    States: str = Field(..., alias=\"States\")\n",
    "    Suspected: str = Field(..., alias=\"Suspected\")\n",
    "    Confirmed: str = Field(..., alias=\"Confirmed\")\n",
    "    Trend: str = Field(..., alias=\"Trend\")\n",
    "    Probable: str = Field(..., alias=\"Probable\")\n",
    "    HCW: str = Field(..., alias=\"HCW*\")\n",
    "    Deaths: str = Field(..., alias=\"Deaths (Confirmed Cases)\")\n",
    "\n",
    "# Define the prompt with instructions to extract JSON formatted output.\n",
    "prompt_template = \"\"\"\n",
    "The provided image contains a table with a section labeled \"Current Week\". Your task is to extract the data from this section only and ignore any cumulative columns.\n",
    "The \"Current Week\" section has the following columns in this exact left-to-right order:\n",
    "1. States\n",
    "2. Suspected\n",
    "3. Confirmed\n",
    "4. Trend\n",
    "5. Probable\n",
    "6. HCW*\n",
    "7. Deaths (Confirmed Cases)\n",
    "\n",
    "Extract the values located under each column header and return the results in JSON format.\n",
    "Return a JSON list of objects, where each object corresponds to one row of the table.\n",
    "Each object must have the following keys (exactly in this order):\n",
    "\"States\", \"Suspected\", \"Confirmed\", \"Trend\", \"Probable\", \"HCW*\", \"Deaths (Confirmed Cases)\"\n",
    "Include one object per state, and the last object should correspond to the \"Total\" row.\n",
    "Ensure that all keys are present in every object, even if some values are blank.\n",
    "Output the JSON in valid format.\n",
    "\"\"\"\n",
    "\n",
    "# Folder containing the PNG images\n",
    "image_folder = \"PDFs_Lines_Test\"  # Adjust this to your local folder name\n",
    "\n",
    "# Get list of PNG images from the folder\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.png\"))\n",
    "if not image_paths:\n",
    "    print(f\"No PNG images found in the folder '{image_folder}'. Please check the folder name and path.\")\n",
    "else:\n",
    "    for image_path in image_paths:\n",
    "        print(\"Processing image:\", image_path)\n",
    "        \n",
    "        # Open the image using Pillow\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Call the Gemini model using structured JSON output.\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[prompt_template, image],\n",
    "                config={\n",
    "                    \"response_mime_type\": \"application/json\",\n",
    "                    \"response_schema\": list[TableRow],\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call for image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Print the raw JSON response text\n",
    "        print(\"Raw JSON response:\")\n",
    "        print(response.text)\n",
    "        \n",
    "        # Parse the response into TableRow objects (if supported)\n",
    "        try:\n",
    "            # The client library may provide a parsed attribute containing Pydantic objects.\n",
    "            table_rows = response.parsed  # Expected to be a list of TableRow objects.\n",
    "            print(\"Extracted Table Data (parsed):\")\n",
    "            for row in table_rows:\n",
    "                # Use .dict(by_alias=True) to output keys as specified in the schema.\n",
    "                print(row.dict(by_alias=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response for image {image_path}: {e}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3 - same as option 2 but saving combined json as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in your .env file. Please add it and restart the notebook.\")\n",
    "\n",
    "# Initialize the Gemini client with your API key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Define the Pydantic model for one row of the table.\n",
    "# Field aliases are used so that the JSON keys match the column names exactly.\n",
    "class TableRow(BaseModel):\n",
    "    States: str = Field(..., alias=\"States\")\n",
    "    Suspected: str = Field(..., alias=\"Suspected\")\n",
    "    Confirmed: str = Field(..., alias=\"Confirmed\")\n",
    "    Trend: str = Field(..., alias=\"Trend\")\n",
    "    Probable: str = Field(..., alias=\"Probable\")\n",
    "    HCW: str = Field(..., alias=\"HCW*\")\n",
    "    Deaths: str = Field(..., alias=\"Deaths (Confirmed Cases)\")\n",
    "\n",
    "# Define the prompt with instructions to extract JSON formatted output.\n",
    "prompt_template = \"\"\"\n",
    "The provided image contains a table with a section labeled \"Current Week\". Your task is to extract the data from this section only and ignore any cumulative columns.\n",
    "The \"Current Week\" section has the following columns in this exact left-to-right order:\n",
    "1. States\n",
    "2. Suspected\n",
    "3. Confirmed\n",
    "4. Trend\n",
    "5. Probable\n",
    "6. HCW*\n",
    "7. Deaths (Confirmed Cases)\n",
    "\n",
    "Extract the values located under each column header and return the results in JSON format.\n",
    "Return a JSON list of objects, where each object corresponds to one row of the table.\n",
    "Each object must have the following keys (exactly in this order):\n",
    "\"States\", \"Suspected\", \"Confirmed\", \"Trend\", \"Probable\", \"HCW*\", \"Deaths (Confirmed Cases)\".\n",
    "\"Trend\" column may contain either blank cells, or one of two types of triangles: ▲ (Up, red triangle) or ▼ (Down, green triangle). You should input either \"Up\" or \"Down\" as a value.\n",
    "Include one object per state, and the last object should correspond to the \"Total\" row.\n",
    "Ensure that all keys are present in every object, even if some values are blank.\n",
    "Output the JSON in valid format.\n",
    "\"\"\"\n",
    "\n",
    "# Folder containing the PNG images\n",
    "image_folder = \"PDFs_Lines_Test\"  # Adjust this to your local folder name\n",
    "\n",
    "# Get list of PNG images from the folder\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.png\"))\n",
    "if not image_paths:\n",
    "    print(f\"No PNG images found in the folder '{image_folder}'. Please check the folder name and path.\")\n",
    "else:\n",
    "    # Define the CSV header in the exact order we expect:\n",
    "    fieldnames = [\n",
    "        \"States\",\n",
    "        \"Suspected\",\n",
    "        \"Confirmed\",\n",
    "        \"Trend\",\n",
    "        \"Probable\",\n",
    "        \"HCW*\",\n",
    "        \"Deaths (Confirmed Cases)\"\n",
    "    ]\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        print(\"Processing image:\", image_path)\n",
    "        \n",
    "        # Open the image using Pillow\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Call the Gemini model using structured JSON output.\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[prompt_template, image],\n",
    "                config={\n",
    "                    \"response_mime_type\": \"application/json\",\n",
    "                    \"response_schema\": list[TableRow],\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call for image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Print the raw JSON response text for debugging\n",
    "        print(\"Raw JSON response:\")\n",
    "        print(response.text)\n",
    "        \n",
    "        # Parse the response into TableRow objects (if supported)\n",
    "        try:\n",
    "            table_rows = response.parsed  # Expected to be a list of TableRow objects.\n",
    "            print(\"Extracted Table Data (parsed):\")\n",
    "            for row in table_rows:\n",
    "                print(row.dict(by_alias=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response for image {image_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Create a CSV filename based on the image filename and save into the CSV_LF folder\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        csv_filename = os.path.join(\"CSV_LF\", f\"{base_filename}.csv\")\n",
    "        \n",
    "        # Write the extracted data to CSV\n",
    "        try:\n",
    "            with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                for row in table_rows:\n",
    "                    # Convert each TableRow to a dict using aliases to preserve key names.\n",
    "                    writer.writerow(row.dict(by_alias=True))\n",
    "            print(f\"CSV file saved as: {csv_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing CSV for image {image_path}: {e}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 4 - 2 API calls per image to ensure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: PDFs_Lines_Test/Lines_Nigeria_16_Dec_24_W51_page3.png\n",
      "Both outputs are identical. Saving CSV.\n",
      "CSV file saved as: CSV_LF/Lines_Nigeria_16_Dec_24_W51_page3.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Processing image: PDFs_Lines_Test/Lines_Nigeria_29_Aug_24_W35_page3.png\n",
      "Both outputs are identical. Saving CSV.\n",
      "CSV file saved as: CSV_LF/Lines_Nigeria_29_Aug_24_W35_page3.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Processing image: PDFs_Lines_Test/Lines_Nigeria_27_Jun_24_W26_page3.png\n",
      "Both outputs are identical. Saving CSV.\n",
      "CSV file saved as: CSV_LF/Lines_Nigeria_27_Jun_24_W26_page3.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Processing image: PDFs_Lines_Test/Lines_Nigeria_21_Mar_24_W12_page3.png\n",
      "Both outputs are identical. Saving CSV.\n",
      "CSV file saved as: CSV_LF/Lines_Nigeria_21_Mar_24_W12_page3.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Processing image: PDFs_Lines_Test/Lines_Nigeria_04_Jan_24_W1_page3.png\n",
      "Both outputs are identical. Saving CSV.\n",
      "CSV file saved as: CSV_LF/Lines_Nigeria_04_Jan_24_W1_page3.csv\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in your .env file. Please add it and restart the notebook.\")\n",
    "\n",
    "# Initialize the Gemini client with your API key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Define the Pydantic model for one row of the table.\n",
    "class TableRow(BaseModel):\n",
    "    States: str = Field(..., alias=\"States\")\n",
    "    Suspected: str = Field(..., alias=\"Suspected\")\n",
    "    Confirmed: str = Field(..., alias=\"Confirmed\")\n",
    "    Trend: str = Field(..., alias=\"Trend\")\n",
    "    Probable: str = Field(..., alias=\"Probable\")\n",
    "    HCW: str = Field(..., alias=\"HCW*\")\n",
    "    Deaths: str = Field(..., alias=\"Deaths (Confirmed Cases)\")\n",
    "\n",
    "# Define the prompt with instructions to extract JSON formatted output.\n",
    "prompt_template = \"\"\"\n",
    "The provided image contains a table with a section labeled \"Current Week\". Your task is to extract the data from this section only.\n",
    "The \"Current Week\" section has the following columns in this exact left-to-right order:\n",
    "1. States\n",
    "2. Suspected\n",
    "3. Confirmed\n",
    "4. Trend\n",
    "5. Probable\n",
    "6. HCW*\n",
    "7. Deaths (Confirmed Cases)\n",
    "\n",
    "Extract the values located under each column header and return the results in JSON format.\n",
    "Return a JSON list of objects, where each object corresponds to one row of the table.\n",
    "\n",
    "Each object must have the following keys (exactly in this order):\n",
    "\"States\", \"Suspected\", \"Confirmed\", \"Trend\", \"Probable\", \"HCW*\", \"Deaths (Confirmed Cases)\".\n",
    "\n",
    "\"States\" corresponds to the states of Nigeria: Ondo, Edo, Bauchi, Taraba, Benue, Ebonyi, Kogi, Kaduna, Plateau, Enugu, Cross River, Rivers, Delta, Nasarawa, Anambra, Gombe, Niger, Imo, Jigawa, Bayelsa, Adamawa, Fct, Katsina, Kano, Oyo, Lagos, Ogun, Yobe, Sokoto, Kebbi, Zamfara, Akwa Ibom, Ekiti, Kwara, Borno, Osun, Abia. The last row should correspond to the \"Total\" for all states.\n",
    "If a row is blank and has no value in \"States\" column, you should omit it.\n",
    "\n",
    "\"Trend\" column may contain either blank cells, or one of two types of triangles: ▲ (Up, red triangle) or ▼ (Down, green triangle). You should input either \"Up\" or \"Down\" as a value.\n",
    "\n",
    "Include one object per state, and the last object should correspond to the \"Total\" row.\n",
    "Ensure that all keys are present in every object, even if some values are blank.\n",
    "Output the JSON in valid format.\n",
    "\"\"\"\n",
    "\n",
    "# Folder containing the PNG images\n",
    "image_folder = \"PDFs_Lines_Test\"  # Adjust this to your local folder name\n",
    "\n",
    "# Get list of PNG images from the folder\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.png\"))\n",
    "if not image_paths:\n",
    "    print(f\"No PNG images found in the folder '{image_folder}'. Please check the folder name and path.\")\n",
    "else:\n",
    "    # Define the CSV header in the exact order we expect:\n",
    "    fieldnames = [\n",
    "        \"States\",\n",
    "        \"Suspected\",\n",
    "        \"Confirmed\",\n",
    "        \"Trend\",\n",
    "        \"Probable\",\n",
    "        \"HCW*\",\n",
    "        \"Deaths (Confirmed Cases)\"\n",
    "    ]\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        print(\"Processing image:\", image_path)\n",
    "        \n",
    "        # Open the image using Pillow\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Process the image twice\n",
    "        responses = []\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                response = client.models.generate_content(\n",
    "                    model=\"gemini-2.0-flash\",\n",
    "                    contents=[prompt_template, image],\n",
    "                    config={\n",
    "                        \"response_mime_type\": \"application/json\",\n",
    "                        \"response_schema\": list[TableRow],\n",
    "                    }\n",
    "                )\n",
    "                responses.append(response)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during API call for image {image_path} on iteration {i+1}: {e}\")\n",
    "                responses = []\n",
    "                break  # Skip to next image if there's an error\n",
    "\n",
    "        if len(responses) != 2:\n",
    "            print(\"Skipping image due to API call errors.\")\n",
    "            continue\n",
    "\n",
    "        # Parse the responses into lists of TableRow objects\n",
    "        try:\n",
    "            table_rows_1 = responses[0].parsed  # List[TableRow]\n",
    "            table_rows_2 = responses[1].parsed  # List[TableRow]\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing responses for image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert both lists into lists of dictionaries\n",
    "        dict_rows_1 = [row.dict(by_alias=True) for row in table_rows_1]\n",
    "        dict_rows_2 = [row.dict(by_alias=True) for row in table_rows_2]\n",
    "\n",
    "        # Compare the two outputs\n",
    "        if dict_rows_1 == dict_rows_2:\n",
    "            print(\"Both outputs are identical. Saving CSV.\")\n",
    "            # Create a CSV filename based on the image filename\n",
    "            base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            csv_filename = os.path.join(\"CSV_LF\", f\"{base_filename}.csv\")\n",
    "            # Write the extracted data to CSV\n",
    "            try:\n",
    "                with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    for row in dict_rows_1:\n",
    "                        writer.writerow(row)\n",
    "                print(f\"CSV file saved as: {csv_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing CSV for image {image_path}: {e}\")\n",
    "        else:\n",
    "            print(\"Outputs differ between iterations for image:\", image_path)\n",
    "            # Identify differing rows\n",
    "            min_len = min(len(dict_rows_1), len(dict_rows_2))\n",
    "            differences_found = False\n",
    "            \n",
    "            for i in range(min_len):\n",
    "                if dict_rows_1[i] != dict_rows_2[i]:\n",
    "                    differences_found = True\n",
    "                    print(f\"Difference in row {i+1}:\")\n",
    "                    print(\"Iteration 1:\", dict_rows_1[i])\n",
    "                    print(\"Iteration 2:\", dict_rows_2[i])\n",
    "            \n",
    "            # Check for any extra rows\n",
    "            if len(dict_rows_1) > min_len:\n",
    "                differences_found = True\n",
    "                print(\"Additional rows in iteration 1:\")\n",
    "                for i in range(min_len, len(dict_rows_1)):\n",
    "                    print(f\"Row {i+1}:\", dict_rows_1[i])\n",
    "            if len(dict_rows_2) > min_len:\n",
    "                differences_found = True\n",
    "                print(\"Additional rows in iteration 2:\")\n",
    "                for i in range(min_len, len(dict_rows_2)):\n",
    "                    print(f\"Row {i+1}:\", dict_rows_2[i])\n",
    "            \n",
    "            if not differences_found:\n",
    "                print(\"No individual row differences were found, despite overall inequality.\")\n",
    "            \n",
    "            print(\"Skipping CSV saving for this image due to inconsistency.\")\n",
    "        \n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5787878787878787"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGE_FOLDER = 'PDFs_Lines_Test'  # Folder containing your PNG images.  Relative path is OK.\n",
    "\n",
    "\n",
    "def detect_text_and_tables(image_path):\n",
    "    \"\"\"Detects text and attempts basic table structure extraction from an image.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple: (extracted_text, table_data)\n",
    "        - extracted_text:  Raw text extracted from the image (string).\n",
    "        - table_data: A list of lists representing the extracted table data.\n",
    "                      Each inner list represents a row.  Returns None if no table\n",
    "                      structure is reasonably detected.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Perform text detection (OCR)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    extracted_text = response.full_text_annotation.text\n",
    "    \n",
    "    # --- Attempt Table Extraction ---\n",
    "    table_data = extract_table_data(response)  # Use the helper function\n",
    "\n",
    "    return extracted_text, table_data\n",
    "\n",
    "def extract_table_data(response):\n",
    "    \"\"\"\n",
    "    Extracts table data from the Google Cloud Vision API response. This uses\n",
    "    block structure, paragraph and word structure, row and column detection.\n",
    "\n",
    "    Args:\n",
    "        response:  The full response from client.document_text_detection().\n",
    "\n",
    "    Returns:\n",
    "        A list of lists representing the extracted table data, or None if\n",
    "        no table-like structure is found.\n",
    "    \"\"\"\n",
    "    blocks = response.full_text_annotation.pages[0].blocks\n",
    "    \n",
    "    # 1. Organize bounding box information for efficient lookup.\n",
    "    bounding_boxes = {}  # Key: (page, block, paragraph, word), Value: BoundingBox\n",
    "    for page_num, page in enumerate(response.full_text_annotation.pages):\n",
    "        for block_num, block in enumerate(page.blocks):\n",
    "            for paragraph_num, paragraph in enumerate(block.paragraphs):\n",
    "                for word_num, word in enumerate(paragraph.words):\n",
    "                    bounding_boxes[(page_num, block_num, paragraph_num, word_num)] = word.bounding_box\n",
    "    \n",
    "    #Helper function to get bounding vertices for paragraphs\n",
    "    def get_paragraph_bounds(paragraph):\n",
    "      \"\"\"Extracts bounding box vertices from a paragraph.\"\"\"\n",
    "      min_x = float('inf')\n",
    "      min_y = float('inf')\n",
    "      max_x = float('-inf')\n",
    "      max_y = float('-inf')\n",
    "\n",
    "      for word in paragraph.words:\n",
    "        for symbol in word.symbols:\n",
    "          for vertex in symbol.bounding_box.vertices:\n",
    "            min_x = min(min_x, vertex.x)\n",
    "            min_y = min(min_y, vertex.y)\n",
    "            max_x = max(max_x, vertex.x)\n",
    "            max_y = max(max_y, vertex.y)\n",
    "      return min_x, min_y, max_x, max_y\n",
    "\n",
    "    # 2. Create data structure for paragraphs (rows)\n",
    "    paragraphs_data = []\n",
    "    \n",
    "    for page_num, page in enumerate(response.full_text_annotation.pages):\n",
    "      for block_num, block in enumerate(page.blocks):\n",
    "          for paragraph_num, paragraph in enumerate(block.paragraphs):\n",
    "            min_x, min_y, max_x, max_y = get_paragraph_bounds(paragraph) # Get Paragraph bounds\n",
    "            paragraph_text = \"\"\n",
    "            for word in paragraph.words:\n",
    "                for symbol in word.symbols:\n",
    "                    paragraph_text += symbol.text\n",
    "            paragraphs_data.append({\n",
    "                'text': paragraph_text,\n",
    "                'min_x': min_x,\n",
    "                'min_y': min_y,\n",
    "                'max_x': max_x,\n",
    "                'max_y': max_y,\n",
    "            })\n",
    "        \n",
    "    # 3. Sort paragraphs_data by 'min_y' (top to bottom), then by 'min_x' (left to right)\n",
    "    paragraphs_data.sort(key=lambda p: (p['min_y'], p['min_x']))\n",
    "    \n",
    "    \n",
    "    #4. Row detection\n",
    "    \n",
    "    rows = []\n",
    "    current_row = []\n",
    "    if paragraphs_data:\n",
    "        # Initialize with the y-coordinate of the first paragraph\n",
    "        current_row_y_center = paragraphs_data[0]['min_y']\n",
    "        row_height_estimate = paragraphs_data[0]['max_y'] - paragraphs_data[0]['min_y'] #initial height estimation\n",
    "        \n",
    "        tolerance_y = row_height_estimate * 0.5 # Allow the row height to vary \n",
    "        \n",
    "        for paragraph in paragraphs_data:\n",
    "            paragraph_y_center = (paragraph['min_y'] + paragraph['max_y']) / 2\n",
    "            \n",
    "            if abs(paragraph_y_center - current_row_y_center) <= tolerance_y :\n",
    "                current_row.append(paragraph)\n",
    "                \n",
    "            else:\n",
    "                # Sort current row by x coordinate before saving it\n",
    "                current_row.sort(key=lambda p: p['min_x'])\n",
    "                rows.append(current_row)\n",
    "                current_row = [paragraph]  # start new row\n",
    "                current_row_y_center = paragraph_y_center  #update Y of current row\n",
    "                row_height_estimate = paragraph['max_y'] - paragraph['min_y']\n",
    "                tolerance_y = row_height_estimate * 0.5 #update the tolerance\n",
    "    \n",
    "    # Append the last row if it's not empty\n",
    "    if current_row:\n",
    "        current_row.sort(key=lambda p: p['min_x'])\n",
    "        rows.append(current_row)\n",
    "        \n",
    "    \n",
    "    # 5. Convert to list of lists (text only) for the table\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        row_data = [p['text'] for p in row]\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    if not table_data:\n",
    "        return None  # No table-like structure found\n",
    "    return table_data\n",
    "\n",
    "\n",
    "def process_images(image_folder):\n",
    "    \"\"\"Processes all PNG images in a folder, extracting text and tables.\"\"\"\n",
    "\n",
    "    all_results = {}  # Store results for each image\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.lower().endswith('.png'):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            print(f\"Processing: {filename}\")\n",
    "\n",
    "            extracted_text, table_data = detect_text_and_tables(image_path)\n",
    "\n",
    "            all_results[filename] = {\n",
    "                'text': extracted_text,\n",
    "                'table': table_data\n",
    "            }\n",
    "\n",
    "            # Print results (optional, for immediate feedback)\n",
    "            print(f\"Extracted Text:\\n{extracted_text}\\n\")\n",
    "\n",
    "            if table_data:\n",
    "                print(\"Extracted Table:\")\n",
    "                df = pd.DataFrame(table_data)\n",
    "                print(df.to_string()) #Use Panda for better printing\n",
    "            else:\n",
    "                print(\"No table found.\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    results = process_images(IMAGE_FOLDER)\n",
    "\n",
    "    # --- Post-Processing (Example: Saving results to files) ---\n",
    "    # You can now further process the 'results' dictionary.  For example:\n",
    "\n",
    "    \"\"\" for filename, data in results.items():\n",
    "        # Save extracted text to a .txt file\n",
    "        text_filename = os.path.join(IMAGE_FOLDER, f\"{filename.split('.')[0]}_text.txt\")\n",
    "        with open(text_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(data['text'])\n",
    "\n",
    "        # Save table data to a .csv file (if a table was found)\n",
    "        if data['table']:\n",
    "            table_filename = os.path.join(IMAGE_FOLDER, f\"{filename.split('.')[0]}_table.csv\")\n",
    "            df = pd.DataFrame(data['table'])\n",
    "            df.to_csv(table_filename, index=False, header=False)  # Save without row indices or headers \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Lines_Nigeria_21_Mar_24_W12_page3.png\n",
      "An unexpected error occurred: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load Environment Variables ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGE_FOLDER = 'PDFs_Lines_Test'  # Your image folder\n",
    "\n",
    "def detect_table_structure(image_path):\n",
    "    \"\"\"Detects table structure (lines) using OpenCV, handling no-line cases.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image.\n",
    "\n",
    "    Returns:\n",
    "        A tuple: (horizontal_lines, vertical_lines, image_gray).\n",
    "        - horizontal_lines:  Detected horizontal lines or an empty list if none.\n",
    "        - vertical_lines: Detected vertical lines or an empty list if none.\n",
    "        - image_gray: The grayscale image (or None if loading failed).\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not open or read image at {image_path}\")\n",
    "\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # --- Thresholding (Binarization) ---\n",
    "    thresh = cv2.adaptiveThreshold(~image_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "    # --- Horizontal Line Detection ---\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "    horizontal_lines = cv2.erode(thresh, horizontal_kernel, iterations=3)\n",
    "    horizontal_lines = cv2.dilate(horizontal_lines, horizontal_kernel, iterations=3)\n",
    "\n",
    "    # --- Vertical Line Detection ---\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "    vertical_lines = cv2.erode(thresh, vertical_kernel, iterations=3)\n",
    "    vertical_lines = cv2.dilate(vertical_lines, vertical_kernel, iterations=3)\n",
    "    \n",
    "    return horizontal_lines, vertical_lines, image_gray\n",
    "\n",
    "\n",
    "def get_table_cells(horizontal_lines, vertical_lines, image_gray):\n",
    "    \"\"\"\n",
    "       Gets the bounding box coordinates of table cells based on detected lines.\n",
    "       Creates and empty table of dimensions as detected by number of intersections\n",
    "\n",
    "    Args:\n",
    "        horizontal_lines:  Result from detect_table_structure.\n",
    "        vertical_lines: Result from detect_table_structure.\n",
    "        image_gray: Grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists representing the table cells' bounding box coordinates,\n",
    "        where each inner list represents a row, and each element in the inner\n",
    "        list is a tuple: (x1, y1, x2, y2).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Combine Lines and Find Contours ---\n",
    "    table_lines = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)\n",
    "    table_lines = cv2.erode(~table_lines, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)), iterations=1)\n",
    "    (T, thresh) = cv2.threshold(table_lines, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]  # Handle different OpenCV versions\n",
    "\n",
    "    # --- Get Bounding Boxes of Cells ---\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, x + w, y + h))\n",
    "    \n",
    "    # --- Sort Bounding Boxes (Top-to-Bottom, Then Left-to-Right) ---\n",
    "    bounding_boxes.sort(key=lambda bbox: (bbox[1], bbox[0])) # Sort by y first, x second\n",
    "    \n",
    "    # --- Determine Table Dimensions ---\n",
    "    # Estimate number of columns and rows based on lines, not contours\n",
    "    #This is more accurate, and then we map extracted contours to the empty table\n",
    "    \n",
    "    lines_v = cv2.HoughLinesP(vertical_lines, 1, np.pi / 180, 200, minLineLength=20, maxLineGap=15)\n",
    "    lines_h = cv2.HoughLinesP(horizontal_lines, 1, np.pi / 180, 200, minLineLength=20, maxLineGap=15)\n",
    "\n",
    "    #Count the number of lines to estimate columns and rows.\n",
    "    if lines_v is not None:\n",
    "        num_columns = len(lines_v)\n",
    "    else:\n",
    "        num_columns = 0  # No Vertical Lines\n",
    "\n",
    "    if lines_h is not None:\n",
    "        num_rows = len(lines_h)\n",
    "    else:\n",
    "        num_rows = 0\n",
    "    \n",
    "    #Create Empty Table Structure of cells\n",
    "    if (num_rows > 0) and (num_columns > 0):\n",
    "        table_cells = [[None for _ in range(num_columns)] for _ in range(num_rows)]\n",
    "        # --- Map Bounding Boxes to Cells ---\n",
    "        # Fill in the table structure. We iterate the extracted rectangles and insert\n",
    "        #them into an appropriate cell.\n",
    "        \n",
    "        for x1, y1, x2, y2 in bounding_boxes:\n",
    "            cell_assigned = False\n",
    "            for i in range(num_rows):\n",
    "                for j in range(num_columns):\n",
    "                    # Check if we already have a box in table cell\n",
    "                    if table_cells[i][j] is None:\n",
    "                        # Check if current coordinates intersect with the area that a particular table cell would cover\n",
    "                        # Get Line coordinates (extrapolate a bit to not miss edge cases)\n",
    "                        y_start = lines_h[i][0][1] - 5 if lines_h is not None else y1 # use y from the box as backup\n",
    "                        y_end = lines_h[i+1][0][1] + 5 if i+1<len(lines_h) and lines_h is not None else y2  # use y from the box as backup\n",
    "                        \n",
    "                        x_start = lines_v[j][0][0] - 5 if lines_v is not None else x1 # use x from the box as backup\n",
    "                        x_end = lines_v[j+1][0][0] + 5 if j+1 < len(lines_v) and lines_v is not None else x2 # use x from the box as backup\n",
    "                        \n",
    "                        \n",
    "                        # Check for overlap\n",
    "                        if (x1 >= x_start and x2 <= x_end and\n",
    "                           y1 >= y_start and y2 <= y_end):\n",
    "                            \n",
    "                            #Store Bounding box into that cell.\n",
    "                            table_cells[i][j] = (x1, y1, x2, y2)\n",
    "                            cell_assigned = True\n",
    "                            break   #exit column\n",
    "                if cell_assigned:\n",
    "                    break   # exit row\n",
    "    else:\n",
    "        table_cells = [] #return empty table if error in HoughLines\n",
    "\n",
    "    return table_cells\n",
    "\n",
    "def extract_text_from_cells(table_cells, image_gray, client):\n",
    "    \"\"\"Extracts text from each cell using Google Cloud Vision API.\n",
    "\n",
    "    Args:\n",
    "        table_cells: The list of lists representing cell bounding boxes.\n",
    "        image_gray:  The grayscale image.\n",
    "        client: The Google Cloud Vision API client.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists representing the extracted text from each cell.\n",
    "    \"\"\"\n",
    "    table_text = []\n",
    "\n",
    "    for row_cells in table_cells:\n",
    "        row_text = []\n",
    "        for x1, y1, x2, y2 in row_cells:\n",
    "            if (x1, y1, x2, y2) is not None:\n",
    "                # Crop the cell region from the grayscale image\n",
    "                cell_image = image_gray[y1:y2, x1:x2]\n",
    "\n",
    "                # Convert the OpenCV image to bytes (required by Vision API)\n",
    "                _, encoded_image = cv2.imencode('.png', cell_image)\n",
    "                content = encoded_image.tobytes()\n",
    "                image = types.Image(content=content)\n",
    "\n",
    "                # Perform OCR on the cell image\n",
    "                response = client.document_text_detection(image=image)\n",
    "                cell_text = response.full_text_annotation.text if response.full_text_annotation else \"\"\n",
    "\n",
    "                row_text.append(cell_text)\n",
    "            else:\n",
    "                row_text.append(\"\") #handle empty cells\n",
    "        table_text.append(row_text)\n",
    "\n",
    "    return table_text\n",
    "\n",
    "\n",
    "def detect_text_and_tables(image_path):\n",
    "    \"\"\"Main function to detect text and tables, handling errors.\"\"\"\n",
    "    try:\n",
    "        horizontal_lines, vertical_lines, image_gray = detect_table_structure(image_path)\n",
    "        table_cells = get_table_cells(horizontal_lines, vertical_lines, image_gray)\n",
    "\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        table_data = extract_text_from_cells(table_cells, image_gray, client)\n",
    "\n",
    "        # Extract all text from the image (for the 'extracted_text' part)\n",
    "        with io.open(image_path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "        image = types.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "        extracted_text = response.full_text_annotation.text\n",
    "\n",
    "        return extracted_text, table_data\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def process_images(image_folder):\n",
    "    \"\"\"Processes images and extracts text/tables.\"\"\"\n",
    "    all_results = {}\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.lower().endswith('.png'):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            print(f\"Processing: {filename}\")\n",
    "\n",
    "            try:  # Add a try-except block here\n",
    "                extracted_text, table_data = detect_text_and_tables(image_path)\n",
    "            except TypeError as e:\n",
    "                print(f\"TypeError occurred: {e}\")\n",
    "                import pdb; pdb.set_trace()  # Add this line!\n",
    "                extracted_text, table_data = None, None #placeholder to avoid further errors.\n",
    "\n",
    "            if extracted_text is not None:\n",
    "                all_results[filename] = {\n",
    "                    'text': extracted_text,\n",
    "                    'table': table_data\n",
    "                }\n",
    "\n",
    "                print(f\"Extracted Text:\\n{extracted_text}\\n\")\n",
    "                if table_data:\n",
    "                    print(\"Extracted Table:\")\n",
    "                    df = pd.DataFrame(table_data)\n",
    "                    print(df.to_string())  # Use Pandas for better printing\n",
    "                else:\n",
    "                    print(\"No table found.\")\n",
    "                print(\"-\" * 40)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if not os.path.exists(IMAGE_FOLDER):\n",
    "        os.makedirs(IMAGE_FOLDER)\n",
    "\n",
    "    results = process_images(IMAGE_FOLDER)\n",
    "\n",
    "    \"\"\" for filename, data in results.items():\n",
    "        text_filename = os.path.join(IMAGE_FOLDER, f\"{filename.split('.')[0]}_text.txt\")\n",
    "        with open(text_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(data['text'])\n",
    "        if data['table']:\n",
    "            table_filename = os.path.join(IMAGE_FOLDER, f\"{filename.split('.')[0]}_table.csv\")\n",
    "            df = pd.DataFrame(data['table'])\n",
    "            df.to_csv(table_filename, index=False, header=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "extracted_text, table_data = detect_text_and_tables(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lines_Nigeria_21_Mar_24_W12_page3.png': {'text': 'Epi Week: 12 2024\\nCumulative (Week 1 - 12)\\nCases\\nDeaths\\nLassa Fever Situation Report\\nTable 3. Weekly and Cumulative number of suspected and confirmed cases for 2024\\nCurrent week: (Week 12)\\nCases\\nDeaths\\nStates\\nSuspected Confirmed Trend Probable HCW* (Confirmed Cases) Suspected Confirmed Probable HCW* (Confirmed Cases)\\n1 Ondo\\n60\\n8\\n1026\\n184\\n3\\n13\\n2 Edo\\n77\\n4\\n1171\\n178\\n1\\n23\\n3 Bauchi\\n34\\n4❘ Taraba\\n27\\n5 Benue\\n29\\n352\\n1\\n566\\n123\\n3\\n27\\n1\\n190\\n95\\n3\\n20\\n2\\n999\\n62\\n9\\n8\\n00\\n11\\n6 Ebonyi\\n17\\n1\\n1\\n213\\n43\\n6\\n24\\n7 Kogi\\n2\\n1\\n1\\n94\\n28\\n1\\n1\\n2\\n8 Kaduna\\n7\\n97\\n15\\n2\\n3\\n8\\n9 Plateau\\n9\\n1\\n63\\n9\\n10 Enugu\\n1\\n63\\n8\\n1\\n11 Cross River\\n12\\n1\\n45\\n7\\n1\\n12 Rivers\\n56\\n5\\n3\\n13 Delta\\n3\\n54\\n4\\n2\\n14 Anambra\\n1\\n17\\n4\\n1\\n3\\n15 Nasarawa\\n37\\n4\\n1\\n1\\n16 Niger\\n8\\n3\\nN\\n17 Gombe\\n25\\n3\\n5\\n1\\n18 Imo\\n2\\n30\\n3\\n1\\n2\\n19 Jigawa\\n2\\n22\\n2\\n1\\n20 Bayelsa\\n1\\n14\\n21 Adamawa\\n1\\n12\\n22 Fct\\n1\\n42\\nN N N\\n2\\n1\\n23 Kano\\n2\\n45\\n1\\n24 Oyo\\n1\\n21\\n1\\n1\\n25 Lagos\\n1\\n26\\n1\\n26 Ogun\\n5\\n20\\n1\\n1\\n1\\n27 Yobe\\n14\\n1\\n1\\n2\\n2\\n28 Kebbi\\n29 Zamfara\\n30 Akwa Ibom\\n31 Ekiti\\nN\\n32 Kwara\\n1\\n33 Katsina\\n2\\n34 Borno\\n1\\n35 Osun\\n36 Abia\\n20\\n135527∞\\n8\\nTotal\\n303\\n25\\n0\\n1\\n6\\n5029\\n791\\n17\\n32\\n149',\n",
       "  'table': [['LassaFeverSituationReport'],\n",
       "   ['EpiWeek:122024'],\n",
       "   ['Table3.WeeklyandCumulativenumberofsuspectedandconfirmedcasesfor2024'],\n",
       "   ['Currentweek:(Week12)', 'Cumulative(Week1-12)'],\n",
       "   ['Cases', 'Deaths', 'Cases', 'Deaths'],\n",
       "   ['States'],\n",
       "   ['SuspectedConfirmedTrendProbableHCW*(ConfirmedCases)SuspectedConfirmedProbableHCW*(ConfirmedCases)'],\n",
       "   ['1Ondo', '60', '8', '1026', '184', '3', '13'],\n",
       "   ['2Edo', '77', '4', '1171', '178', '1', '23'],\n",
       "   ['4❘Taraba',\n",
       "    '3Bauchi',\n",
       "    '5Benue',\n",
       "    '27',\n",
       "    '29',\n",
       "    '34',\n",
       "    '352',\n",
       "    '2',\n",
       "    '1',\n",
       "    '1',\n",
       "    '566',\n",
       "    '999',\n",
       "    '190',\n",
       "    '123',\n",
       "    '95',\n",
       "    '62',\n",
       "    '9',\n",
       "    '3',\n",
       "    '8',\n",
       "    '3',\n",
       "    '00',\n",
       "    '27',\n",
       "    '20',\n",
       "    '11'],\n",
       "   ['6Ebonyi', '17', '1', '1', '213', '43', '6', '24'],\n",
       "   ['7Kogi', '2', '1', '1', '94', '28', '1', '1', '2'],\n",
       "   ['8Kaduna', '7', '97', '15', '2', '3', '8'],\n",
       "   ['9Plateau', '9', '1', '63', '9'],\n",
       "   ['10Enugu', '1', '63', '8', '1'],\n",
       "   ['11CrossRiver', '12', '1', '45', '7', '1'],\n",
       "   ['12Rivers', '56', '5', '3'],\n",
       "   ['13Delta', '3', '54', '4', '2'],\n",
       "   ['14Anambra', '1', '17', '4', '1', '3'],\n",
       "   ['15Nasarawa', '37', '4', '1', '1'],\n",
       "   ['16Niger', '8', '3', 'N'],\n",
       "   ['17Gombe', '25', '3', '5', '1'],\n",
       "   ['18Imo', '2', '30', '3', '1', '2'],\n",
       "   ['19Jigawa', '2', '22', '2', '1'],\n",
       "   ['20Bayelsa'],\n",
       "   ['21Adamawa', '22Fct', '1', '1', '1', '42', '14', '12', '2', 'NNN', '1'],\n",
       "   ['23Kano', '2', '45', '1'],\n",
       "   ['24Oyo', '1', '21', '1', '1'],\n",
       "   ['25Lagos', '1', '26', '1'],\n",
       "   ['26Ogun', '5', '20', '1', '1', '1'],\n",
       "   ['27Yobe', '14', '1', '1'],\n",
       "   ['28Kebbi', '2', '2'],\n",
       "   ['30AkwaIbom',\n",
       "    '29Zamfara',\n",
       "    '32Kwara',\n",
       "    '33Katsina',\n",
       "    '34Borno',\n",
       "    '35Osun',\n",
       "    '31Ekiti',\n",
       "    '1',\n",
       "    '2',\n",
       "    '1',\n",
       "    'N',\n",
       "    '20',\n",
       "    '135527∞'],\n",
       "   ['36Abia', '8'],\n",
       "   ['Total', '303', '25', '0', '1', '6', '5029', '791', '17', '32', '149']]}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15% left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def hex_to_hsv(hex_color):\n",
    "    rgb = ImageColor.getcolor(hex_color, \"RGB\")\n",
    "    r, g, b = [x / 255.0 for x in rgb]\n",
    "    hsv = cv2.cvtColor(\n",
    "        np.uint8([[[b * 255, g * 255, r * 255]]]),\n",
    "        cv2.COLOR_BGR2HSV\n",
    "    )[0][0]\n",
    "    return hsv\n",
    "\n",
    "def enhance_table_lines_from_pdf_hq(pdf_path, output_path, page_number=0, dpi=300):\n",
    "    \"\"\"\n",
    "    Enhances vertical column separators and draws horizontal lines at\n",
    "    top boundary, bottom boundary, and header bottom.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF.\n",
    "        output_path (str): Path to save the image (use .png).\n",
    "        page_number (int): Page to process (0-indexed).\n",
    "        dpi (int): Resolution for rendering the PDF page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "\n",
    "    # 1. Render the PDF page at high DPI\n",
    "    pix = page.get_pixmap(dpi=dpi) \n",
    "    img_pil = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    # Convert PIL Image to OpenCV BGR\n",
    "    img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 2. Convert to HSV & detect green rows\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # We'll only check the left 15% of the page's width\n",
    "    left_15_width = int(width * 0.15)\n",
    "\n",
    "    target_hsv = hex_to_hsv(\"#D8EDCF\")\n",
    "    tolerance = 15\n",
    "    lower_green = np.array([max(0, target_hsv[0] - tolerance), 50, 50])\n",
    "    upper_green = np.array([min(179, target_hsv[0] + tolerance), 255, 255])\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # Sum only the left 15% columns\n",
    "    green_mask_left = green_mask[:, :left_15_width]\n",
    "    h_proj_green = np.sum(green_mask_left, axis=1)\n",
    "    green_row_indices = np.where(h_proj_green > 0)[0]\n",
    "\n",
    "    if len(green_row_indices) == 0:\n",
    "        print(\"No green rows detected.\")\n",
    "        return\n",
    "\n",
    "    top_boundary = green_row_indices[0]\n",
    "    bottom_boundary = green_row_indices[-1]\n",
    "\n",
    "    # 3. Header Row Detection (just above top_boundary)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    header_region = gray[:top_boundary, :]\n",
    "\n",
    "    # Use Otsu’s threshold for the header\n",
    "    _, binary_header = cv2.threshold(\n",
    "        header_region, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )\n",
    "    h_proj_header = np.sum(binary_header, axis=1)\n",
    "\n",
    "    header_bottom = 0\n",
    "    for i in range(len(h_proj_header) - 1, 0, -1):\n",
    "        if h_proj_header[i] > 40:\n",
    "            header_bottom = i\n",
    "            break\n",
    "\n",
    "    # 4. Adaptive Thresholding in the table region\n",
    "    table_region = gray[top_boundary:bottom_boundary, :]\n",
    "    thresh_table = cv2.adaptiveThreshold(\n",
    "        table_region,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11,\n",
    "        3\n",
    "    )\n",
    "\n",
    "    # 5. Hough Lines to find vertical lines\n",
    "    lines = cv2.HoughLinesP(thresh_table, 1, np.pi / 180,\n",
    "                            threshold=775, minLineLength=10, maxLineGap=8)\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            if abs(x2 - x1) < 5:  # near-vertical\n",
    "                # Adjust back to full image coordinates\n",
    "                vertical_lines.append((x1, y1 + top_boundary, x2, y2 + top_boundary))\n",
    "\n",
    "    # 6. Draw lines on the OpenCV image\n",
    "    # A) Draw the vertical lines from header_bottom to bottom_boundary\n",
    "    for x1, y1, x2, y2 in vertical_lines:\n",
    "        cv2.line(img, (x1, header_bottom), (x2, bottom_boundary), (100, 100, 100), 1)\n",
    "\n",
    "    # B) Draw horizontal lines at top, bottom, and header_bottom\n",
    "    cv2.line(img, (0, top_boundary), (width, top_boundary), (0, 255, 0), 2)     # green\n",
    "    cv2.line(img, (0, bottom_boundary), (width, bottom_boundary), (0, 255, 0), 2) # green\n",
    "    cv2.line(img, (0, header_bottom), (width, header_bottom), (0, 0, 255), 2)  # red\n",
    "\n",
    "    # 7. Convert back to PIL and save\n",
    "    output_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    output_pil.save(output_path)\n",
    "\n",
    "    print(f\"Saved enhanced table to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enhanced table to: Lines_W1_boundaries.png\n",
      "Saved enhanced table to: Lines_W2_boundaries.png\n",
      "Saved enhanced table to: Lines_W3_boundaries.png\n",
      "Saved enhanced table to: Lines_W4_boundaries.png\n",
      "Saved enhanced table to: Lines_W12_boundaries.png\n",
      "Saved enhanced table to: Lines_W22_boundaries.png\n",
      "Saved enhanced table to: Lines_W26_boundaries.png\n",
      "Saved enhanced table to: Lines_W32_boundaries.png\n",
      "Saved enhanced table to: Lines_W42_boundaries.png\n",
      "Saved enhanced table to: Lines_W52_boundaries.png\n"
     ]
    }
   ],
   "source": [
    "for week in [1,2,3,4,12,22,26,32,42,52]:\n",
    "    enhance_table_lines_from_pdf_hq(f\"PDFs/W{week}.pdf\", f\"Lines_W{week}_boundaries.png\", page_number=3, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_lassa_files(folder_path):\n",
    "    \"\"\"\n",
    "    Renames 'An_update_of_Lassa_fever_outbreak_in_Nigeria_041124_45.pdf'\n",
    "    to 'Nigeria_04_Nov_24_W45.pdf', extracting day=04, month=11 => 'Nov', year=24,\n",
    "    and the week number 45.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder that contains the PDF files.\n",
    "    \"\"\"\n",
    "    # For mapping month number to short name\n",
    "    month_map = {\n",
    "        \"01\": \"Jan\", \"02\": \"Feb\", \"03\": \"Mar\", \"04\": \"Apr\",\n",
    "        \"05\": \"May\", \"06\": \"Jun\", \"07\": \"Jul\", \"08\": \"Aug\",\n",
    "        \"09\": \"Sep\", \"10\": \"Oct\", \"11\": \"Nov\", \"12\": \"Dec\",\n",
    "    }\n",
    "\n",
    "    folder = Path(folder_path)\n",
    "    for file_path in folder.iterdir():\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        if not file_path.suffix.lower() == \".pdf\":\n",
    "            continue\n",
    "        \n",
    "        old_name = file_path.name\n",
    "        # Example old_name: \"An_update_of_Lassa_fever_outbreak_in_Nigeria_041124_45.pdf\"\n",
    "        \n",
    "        # 1) Split on underscores\n",
    "        parts = old_name.split(\"_\")\n",
    "        # e.g. [\"An\",\"update\",\"of\",\"Lassa\",\"fever\",\"outbreak\",\"in\",\"Nigeria\",\"041124\",\"45.pdf\"]\n",
    "        \n",
    "        if len(parts) < 9:\n",
    "            # If the file name doesn't match the expected pattern, skip it\n",
    "            print(f\"Skipping file (unrecognized pattern): {old_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 2) The date chunk is parts[8] like \"041124\"\n",
    "        date_str = parts[8]  # \"041124\"\n",
    "        \n",
    "        # 3) The week chunk is in parts[9], but includes \".pdf\" at the end, e.g. \"45.pdf\"\n",
    "        week_str_pdf = parts[9]  # \"45.pdf\"\n",
    "        # Remove \".pdf\" from the end\n",
    "        if week_str_pdf.endswith(\".pdf\"):\n",
    "            week_str = week_str_pdf.replace(\".pdf\", \"\")\n",
    "        else:\n",
    "            print(f\"Skipping file (no .pdf in last part): {old_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 4) date_str should be 6 characters: DDMMYY\n",
    "        if len(date_str) != 6:\n",
    "            print(f\"Skipping file (date string not 6 chars): {old_name}\")\n",
    "            continue\n",
    "        dd = date_str[0:2]   # \"04\"\n",
    "        mm = date_str[2:4]   # \"11\"\n",
    "        yy = date_str[4:6]   # \"24\"\n",
    "        \n",
    "        # 5) Convert mm => month name\n",
    "        month_name = month_map.get(mm, \"???\" )  # fallback \"???\"\n",
    "        \n",
    "        # 6) Build new name\n",
    "        # e.g. \"Nigeria_04_Nov_24_W45.pdf\"\n",
    "        new_name = f\"Nigeria_{dd}_{month_name}_{yy}_W{week_str}.pdf\"\n",
    "        \n",
    "        new_path = folder / new_name\n",
    "        # 7) Rename the file\n",
    "        print(f\"Renaming:\\n  {old_name}\\n-> {new_name}\\n\")\n",
    "        file_path.rename(new_path)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    rename_lassa_files(\"PDFs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
