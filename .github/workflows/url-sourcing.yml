name: NCDC URL Sourcing

on:
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-url-sourcing:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        
    - name: Create data directories
      run: |
        mkdir -p data/raw
        mkdir -p data/processed
        mkdir -p data/documentation
        mkdir -p data/debug
        
    - name: Run URL Sourcing Script
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SCRAPER_API_KEY: ${{ secrets.SCRAPER_API_KEY }}
      run: |
        echo "Running URL Sourcing script..."
        python -c "
        import os
        import logging
        
        # Set up basic logging to console
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Print environment variables (masked)
        db_url = os.environ.get('DATABASE_URL', 'Not set')
        if db_url:
            masked_db_url = db_url[:10] + '...' + db_url[-5:] if len(db_url) > 15 else 'Too short to mask'
            logging.info(f'DATABASE_URL is set: {masked_db_url}')
        else:
            logging.error('DATABASE_URL is not set')
            
        scraper_key = os.environ.get('SCRAPER_API_KEY', 'Not set')
        if scraper_key:
            masked_key = scraper_key[:4] + '...' + scraper_key[-4:] if len(scraper_key) > 8 else 'Too short to mask'
            logging.info(f'SCRAPER_API_KEY is set: {masked_key}')
        else:
            logging.error('SCRAPER_API_KEY is not set')
        "
        
        # Run the actual script
        python src/01_URL_Sourcing.py
